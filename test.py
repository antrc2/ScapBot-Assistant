# from qdrant_client import QdrantClient
# from qdrant_client.models import PointStruct, VectorParams, Distance
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain.schema import Document
# from openai import OpenAI
# import pandas as pd
# import uuid  # ƒê·ªÉ t·∫°o id duy nh·∫•t

# # === Kh·ªüi t·∫°o Qdrant v√† OpenAI ===
# qdrant = QdrantClient(path="database")
# client = OpenAI(base_url="http://26.203.51.178:5555/v1", api_key="dont_need")

# collection_name = "my_collection"

# # === T·∫°o collection n·∫øu ch∆∞a t·ªìn t·∫°i ===
# if collection_name not in [c.name for c in qdrant.get_collections().collections]:
#     qdrant.create_collection(
#         collection_name=collection_name,
#         vectors_config=VectorParams(size=768, distance=Distance.COSINE)  # Size t√πy theo model b·∫°n d√πng
#     )
#     print(f"‚úÖ ƒê√£ t·∫°o collection `{collection_name}`")

# # === H√†m split vƒÉn b·∫£n ===
# def text_split(docs):
#     text_splitter = RecursiveCharacterTextSplitter(
#         chunk_size=512,
#         chunk_overlap=100,
#         separators=["\n\n", "\n", " ", ""],
#         length_function=len
#     )
#     return text_splitter.split_documents(docs)

# # === H√†m l·∫•y embedding t·ª´ API ===
# def embeddingText(text):
#     return client.embeddings.create(
#         model="text-embedding-nomic-embed-text-v1.5",
#         input=text,
#         encoding_format='float'
#     ).data[0].embedding

# # === ƒê·ªçc file Excel v√† x·ª≠ l√Ω ===
# file_path = "data.xlsx"
# all_sheets = pd.read_excel(file_path, sheet_name=None, header=None)

# # === Chu·∫©n b·ªã danh s√°ch PointStruct ƒë·ªÉ ƒë∆∞a v√†o Qdrant ===
# points = []

# for sheet_name, df in all_sheets.items():
#     df_text = "\n".join(df.astype(str).apply(lambda row: " ".join(row), axis=1))
#     document = Document(
#         page_content=df_text,
#         metadata={'source': file_path, 'sheet_name': sheet_name}
#     )
#     documents = text_split([document])

#     for doc in documents:
#         embedding = embeddingText(doc.page_content)
#         point = PointStruct(
#             id=str(uuid.uuid4()),  # id ng·∫´u nhi√™n duy nh·∫•t
#             vector=embedding,
#             payload={
#                 "text": doc.page_content,
#                 "source": doc.metadata.get("source"),
#                 "sheet": doc.metadata.get("sheet_name")
#             }
#         )
#         points.append(point)

# # === ƒê∆∞a v√†o Qdrant ===
# if points:
#     qdrant.upsert(collection_name=collection_name, points=points)
#     print(f"‚úÖ ƒê√£ upsert {len(points)} ƒëi·ªÉm v√†o collection `{collection_name}`")
# else:
#     print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c upsert v√†o Qdrant.")


# query.py
# from qdrant_client import QdrantClient
# from openai import OpenAI

# qdrant = QdrantClient(path="database")
# collection_name = "my_collection"

# client = OpenAI(base_url="http://26.203.51.178:5555/v1", api_key="AIzaSyB45BxMcdiViDPeZnW5lz1y9tRL-z3Vckc")

# def embed(text):
#     return client.embeddings.create(
#         model="text-embedding-nomic-embed-text-v1.5",
#         input=text
#     ).data[0].embedding

# # query = input("‚ùì Nh·∫≠p c√¢u h·ªèi: ")
# query = "ScapBot"
# query_vector = embed(query)

# results = qdrant.search(
#     collection_name=collection_name,
#     query_vector=query_vector,
#     limit=5
# )

# print("\nüìÑ K·∫øt qu·∫£ li√™n quan:")
# for r in results:
#     print(r)
    # print(f"- [{r.payload['source']} - trang {r.payload['page']}]")
    # print(r.payload['text'][:300], "\n---\n")
